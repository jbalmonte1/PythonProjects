{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech-To-Text Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This code implements a speech-to-text translator using IBM Watson Speech-To-Text API and automatically translates it to a foreign language using IBM Watson Translator API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson import SpeechToTextV1\n",
    "from ibm_watson import LanguageTranslatorV3\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Speech-to-Text adapter using authenticator from api key and set the url service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_s2t = \"https://api.jp-tok.speech-to-text.watson.cloud.ibm.com/instances/9f1f30e6-978b-4180-b87a-1ee3a27a80db\"\n",
    "iam_apikey_s2t = \"_KsJe_QRH-z2ZQnwvLkwuA5NAQ4k56tmOZcBepxEbD3A\"\n",
    "\n",
    "authenticator = IAMAuthenticator(iam_apikey_s2t)\n",
    "s2t = SpeechToTextV1(authenticator)\n",
    "s2t.set_service_url(url_s2t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download sample audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "  3 4134k    3  144k    0     0   144k      0  0:00:28  0:00:01  0:00:27 74322\n",
      "  5 4134k    5  224k    0     0  76458      0  0:00:55  0:00:03  0:00:52 74521\n",
      "  6 4134k    6  288k    0     0  98304      0  0:00:43  0:00:03  0:00:40 74024\n",
      "  8 4134k    8  368k    0     0  94208      0  0:00:44  0:00:04  0:00:40 75836\n",
      " 10 4134k   10  448k    0     0  76458      0  0:00:55  0:00:06  0:00:49 93795\n",
      " 11 4134k   11  496k    0     0  72557      0  0:00:58  0:00:07  0:00:51 71645\n",
      " 14 4134k   14  592k    0     0  86601      0  0:00:48  0:00:07  0:00:41 77046\n",
      " 16 4134k   16  672k    0     0  86016      0  0:00:49  0:00:08  0:00:41 78643\n",
      " 18 4134k   18  768k    0     0  78643      0  0:00:53  0:00:10  0:00:43 81415\n",
      " 20 4134k   20  864k    0     0  80430      0  0:00:52  0:00:11  0:00:41 86005\n",
      " 23 4134k   23  976k    0     0  90856      0  0:00:46  0:00:11  0:00:35 99216\n",
      " 26 4134k   26 1088k    0     0  92842      0  0:00:45  0:00:12  0:00:33   98k\n",
      " 29 4134k   29 1200k    0     0  87771      0  0:00:48  0:00:14  0:00:34  104k\n",
      " 31 4134k   31 1296k    0     0  88473      0  0:00:47  0:00:15  0:00:32  105k\n",
      " 34 4134k   34 1424k    0     0  97211      0  0:00:43  0:00:15  0:00:28  113k\n",
      " 37 4134k   37 1568k    0     0  94448      0  0:00:44  0:00:17  0:00:27  117k\n",
      " 40 4134k   40 1680k    0     0    98k      0  0:00:41  0:00:17  0:00:24  118k\n",
      " 43 4134k   43 1792k    0     0  96579      0  0:00:43  0:00:19  0:00:24  118k\n",
      " 46 4134k   46 1903k    0     0   100k      0  0:00:41  0:00:19  0:00:22  122k\n",
      " 48 4134k   48 2016k    0     0   100k      0  0:00:41  0:00:20  0:00:21  118k\n",
      " 50 4134k   50 2095k    0     0  97538      0  0:00:43  0:00:22  0:00:21  103k\n",
      " 52 4134k   52 2176k    0     0  96879      0  0:00:43  0:00:23  0:00:20   98k\n",
      " 54 4134k   54 2272k    0     0    98k      0  0:00:41  0:00:23  0:00:18 99538\n",
      " 58 4134k   58 2416k    0     0  98959      0  0:00:42  0:00:25  0:00:17  100k\n",
      " 61 4134k   61 2528k    0     0  99564      0  0:00:42  0:00:26  0:00:16  101k\n",
      " 63 4134k   63 2640k    0     0    97k      0  0:00:42  0:00:27  0:00:15  110k\n",
      " 66 4134k   66 2736k    0     0    97k      0  0:00:42  0:00:28  0:00:14  110k\n",
      " 68 4134k   68 2832k    0     0  99998      0  0:00:42  0:00:29  0:00:13  111k\n",
      " 70 4134k   70 2912k    0     0   100k      0  0:00:41  0:00:29  0:00:12  100k\n",
      " 72 4134k   72 3008k    0     0  99361      0  0:00:42  0:00:31  0:00:11 97678\n",
      " 74 4134k   74 3087k    0     0    99k      0  0:00:41  0:00:31  0:00:10 91954\n",
      " 77 4134k   77 3184k    0     0    99k      0  0:00:41  0:00:32  0:00:09 93489\n",
      " 79 4134k   79 3280k    0     0  98785      0  0:00:42  0:00:34  0:00:08 91185\n",
      " 81 4134k   81 3360k    0     0    98k      0  0:00:41  0:00:34  0:00:07 92026\n",
      " 83 4134k   83 3456k    0     0    98k      0  0:00:41  0:00:35  0:00:06 92921\n",
      " 86 4134k   86 3567k    0     0  98734      0  0:00:42  0:00:37  0:00:05 97698\n",
      " 89 4134k   89 3695k    0     0    99k      0  0:00:41  0:00:37  0:00:04  102k\n",
      " 92 4134k   92 3824k    0     0    98k      0  0:00:42  0:00:39  0:00:03  109k\n",
      " 95 4134k   95 3968k    0     0    99k      0  0:00:41  0:00:40  0:00:01  120k\n",
      " 99 4134k   99 4096k    0     0   102k      0  0:00:40  0:00:40 --:--:--  128k\n",
      "100 4134k  100 4134k    0     0   100k      0  0:00:41  0:00:41 --:--:--  137k\n"
     ]
    }
   ],
   "source": [
    "!curl -o PolynomialRegressionandPipelines.mp3  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/PY0101EN/labs/PolynomialRegressionandPipelines.mp3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "path = 'PolynomialRegressionandPipelines.mp3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open audio file and call API to convert it to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, mode = 'rb') as audiofile:\n",
    "    response = s2t.recognize(audio = audiofile, content_type = 'audio/mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result_index': 0,\n",
       " 'results': [{'final': True,\n",
       "   'alternatives': [{'transcript': 'in this video we will cover polynomial regression and pipelines ',\n",
       "     'confidence': 0.94}]},\n",
       "  {'final': True,\n",
       "   'alternatives': [{'transcript': \"what do we do when a linear model is not the best fit for our data let's look into another type of regression model the polynomial regression we transform our data into a polynomial then use linear regression to fit the parameters that we will discuss pipelines pipelines are way to simplify your code \",\n",
       "     'confidence': 0.9}]},\n",
       "  {'final': True,\n",
       "   'alternatives': [{'transcript': \"polynomial regression is a special case of the general linear regression this method is beneficial for describing curvilinear relationships what is a curvilinear relationship it's what you get by squaring or setting higher order terms of the predictor variables in the model transforming the data the model can be quadratic which means the predictor variable in the model is squared we use a bracket to indicated as an exponent this is the second order polynomial regression with a figure representing the function \",\n",
       "     'confidence': 0.95}]},\n",
       "  {'final': True,\n",
       "   'alternatives': [{'transcript': 'the model can be cubic which means the predictor variable is cute this is the third order polynomial regression we see by examining the figure that the function has more variation ',\n",
       "     'confidence': 0.95}]},\n",
       "  {'final': True,\n",
       "   'alternatives': [{'transcript': \"there also exists higher order polynomial regressions when a good fit hasn't been achieved by second or third order we can see in figures how much the graphs change when we change the order of the polynomial regression the degree of the regression makes a big difference and can result in a better fit if you pick the right value in all cases the relationship between the variable in the parameter is always linear \",\n",
       "     'confidence': 0.91}]},\n",
       "  {'final': True,\n",
       "   'alternatives': [{'transcript': \"let's look at an example from our data we generate a polynomial regression model \",\n",
       "     'confidence': 0.89}]},\n",
       "  {'final': True,\n",
       "   'alternatives': [{'transcript': 'in python we do this by using the poly fit function in this example we develop a third order polynomial regression model base we can print out the model symbolic form for the model is given by the following expression ',\n",
       "     'confidence': 0.92}]},\n",
       "  {'final': True,\n",
       "   'alternatives': [{'transcript': \"negative one point five five seven X. one cute plus two hundred four point eight X. one squared plus eight thousand nine hundred sixty five X. one plus one point three seven times ten to the power of five we can also have multi dimensional polynomial linear regression the expression can get complicated here are just some of the terms for two dimensional second order polynomial none pies poly fit function cannot perform this type of regression we use the preprocessing librarian scikit learn to create a polynomial feature object the constructor takes the degree of the polynomial as a parameter then we transform the features into a polynomial feature with the fit underscore transform method let's do a more intuitive example \",\n",
       "     'confidence': 0.9}]},\n",
       "  {'final': True,\n",
       "   'alternatives': [{'transcript': 'consider the feature shown here applying the method we transform the data we now have a new set of features that are transformed version of our original features as that I mention of the data gets larger we may want to normalize multiple features as scikit learn instead we can use the preprocessing module to simplify many tasks for example we can standardize each feature simultaneously we import standard scaler we train the object fit the scale object then transform the data into a new data frame on a rate X. underscore scale there are more normalization methods available in the pre processing library as well as other transformations we can simplify our code by using a pipeline library there are many steps to getting a prediction for example normalization polynomial transform and linear regression we simplify the process using a pipeline ',\n",
       "     'confidence': 0.9}]},\n",
       "  {'final': True,\n",
       "   'alternatives': [{'transcript': 'pipeline sequentially perform a series of transformations the last step carries out a prediction first we import all the modules we need then we import the library pipeline we create a list of topples the first element in the topple contains the name of the estimator model the second element contains model constructor we input the list in the pipeline constructor we now have a pipeline object we can train the pipeline by applying the train method to the pipeline object we can also produce a prediction as well ',\n",
       "     'confidence': 0.89}]},\n",
       "  {'final': True,\n",
       "   'alternatives': [{'transcript': 'the method normalizes the data performs a polynomial transform then outputs a prediction ',\n",
       "     'confidence': 0.89}]}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert json object into a paragraph of translated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In this video we will cover polynomial regression and pipelines. What do we do when a linear model is not the best fit for our data let's look into another type of regression model the polynomial regression we transform our data into a polynomial then use linear regression to fit the parameters that we will discuss pipelines pipelines are way to simplify your code. Polynomial regression is a special case of the general linear regression this method is beneficial for describing curvilinear relationships what is a curvilinear relationship it's what you get by squaring or setting higher order terms of the predictor variables in the model transforming the data the model can be quadratic which means the predictor variable in the model is squared we use a bracket to indicated as an exponent this is the second order polynomial regression with a figure representing the function. The model can be cubic which means the predictor variable is cute this is the third order polynomial regression we see by examining the figure that the function has more variation. There also exists higher order polynomial regressions when a good fit hasn't been achieved by second or third order we can see in figures how much the graphs change when we change the order of the polynomial regression the degree of the regression makes a big difference and can result in a better fit if you pick the right value in all cases the relationship between the variable in the parameter is always linear. Let's look at an example from our data we generate a polynomial regression model. In python we do this by using the poly fit function in this example we develop a third order polynomial regression model base we can print out the model symbolic form for the model is given by the following expression. Negative one point five five seven x. one cute plus two hundred four point eight x. one squared plus eight thousand nine hundred sixty five x. one plus one point three seven times ten to the power of five we can also have multi dimensional polynomial linear regression the expression can get complicated here are just some of the terms for two dimensional second order polynomial none pies poly fit function cannot perform this type of regression we use the preprocessing librarian scikit learn to create a polynomial feature object the constructor takes the degree of the polynomial as a parameter then we transform the features into a polynomial feature with the fit underscore transform method let's do a more intuitive example. Consider the feature shown here applying the method we transform the data we now have a new set of features that are transformed version of our original features as that i mention of the data gets larger we may want to normalize multiple features as scikit learn instead we can use the preprocessing module to simplify many tasks for example we can standardize each feature simultaneously we import standard scaler we train the object fit the scale object then transform the data into a new data frame on a rate x. underscore scale there are more normalization methods available in the pre processing library as well as other transformations we can simplify our code by using a pipeline library there are many steps to getting a prediction for example normalization polynomial transform and linear regression we simplify the process using a pipeline. Pipeline sequentially perform a series of transformations the last step carries out a prediction first we import all the modules we need then we import the library pipeline we create a list of topples the first element in the topple contains the name of the estimator model the second element contains model constructor we input the list in the pipeline constructor we now have a pipeline object we can train the pipeline by applying the train method to the pipeline object we can also produce a prediction as well. The method normalizes the data performs a polynomial transform then outputs a prediction.\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '. '.join([sentence.strip().capitalize() for sentence in list(json_normalize(response.result['results'],'alternatives')['transcript'])]) + '.'\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Language Translator adapter using authenticator from api key and set the url service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_lt = \"https://api.jp-tok.language-translator.watson.cloud.ibm.com/instances/fb4e3475-c43e-4c47-8827-2235446d15f6\"\n",
    "iam_apikey_lt = \"xemLAe6Lkf2sJFh5R1_tPZJP3QBTeu6yL18ExyCrFhma\"\n",
    "version_lt='2018-05-01'\n",
    "\n",
    "authenticator = IAMAuthenticator(iam_apikey_lt)\n",
    "lt = LanguageTranslatorV3(version = version_lt, authenticator = authenticator)\n",
    "lt.set_service_url(url_lt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show supported languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "supported_languages = json_normalize(lt.list_identifiable_languages().get_result(), \"languages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search for Italian XD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>af</td>\n",
       "      <td>Afrikaans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ar</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>az</td>\n",
       "      <td>Azerbaijani</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ba</td>\n",
       "      <td>Bashkir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>be</td>\n",
       "      <td>Belarusian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>uk</td>\n",
       "      <td>Ukrainian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>ur</td>\n",
       "      <td>Urdu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>vi</td>\n",
       "      <td>Vietnamese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>zh</td>\n",
       "      <td>Simplified Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>zh-TW</td>\n",
       "      <td>Traditional Chinese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   language                 name\n",
       "0        af            Afrikaans\n",
       "1        ar               Arabic\n",
       "2        az          Azerbaijani\n",
       "3        ba              Bashkir\n",
       "4        be           Belarusian\n",
       "..      ...                  ...\n",
       "71       uk            Ukrainian\n",
       "72       ur                 Urdu\n",
       "73       vi           Vietnamese\n",
       "74       zh   Simplified Chinese\n",
       "75    zh-TW  Traditional Chinese\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supported_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>it</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   language     name\n",
       "31       it  Italian"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supported_languages[supported_languages['name'] == 'Italian']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call API and translate text into target language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'translations': [{'translation': \"In questo video copriremo la regressione polinomiale e i gasdotti. Cosa facciamo quando un modello lineare non è il migliore adatto per i nostri dati, analizziamo un altro tipo di regressione modello la regressione polinomiale che trasformiamo i nostri dati in un polinomio poi usa la regressione lineare per adattarsi ai parametri che discuteremo di pipeline pipeline sono in grado di semplificare il tuo codice. La regressione polinomiale è un caso particolare della regressione lineare generale questo metodo è benefico per descrivere le relazioni curvilinee ciò che è un rapporto curvilineo è ciò che si ottiene per quadratura o impostazione di termini di ordine superiore delle variabili predittiva nel modello che trasforma il dato il modello può essere quadratico che significa la variabile predittiva nel modello è quadrante usiamo una staffa per indicare come esponente questa è la regressione polinomiale di secondo ordine con una figura che rappresenta la funzione. Il modello può essere cubico che significa che la variabile predittiva è carina questa è la regressione polinomiale di terzo ordine che vediamo esaminando la figura che la funzione ha più variazione. Esiste anche regressioni polinomiali di ordine superiore quando un buon adattamento non è stato ottenuto secondo un secondo o terzo ordine possiamo vedere in cifre quanto i grafici cambiano quando modifichiamo l'ordine della regressione polinomiale il grado di regressione fa una grande differenza e può risultare in un adattamento migliore se scegli il giusto valore in tutti i casi il rapporto tra la variabile nel parametro è sempre lineare. Analizziamo un esempio dai nostri dati generiamo un modello di regressione polinomiale. In python lo facciamo utilizzando la funzione poli fit in questo esempio sviluppiamo una base modello di regressione polinomiale di terzo ordine possiamo stampare il modulo simbolico modello per il modello è dato dalla seguente espressione. Negativo un punto cinque cinque x. uno carino più duecento quattro punti x. uno squartato più otto diecimila sessanta sessanta x. uno più un punto tre volte sette volte dieci alla potenza di cinque possiamo anche avere una regressione lineare polinomiale multi - dimensionale l'espressione può diventare complicata qui sono solo alcuni dei termini per due dimensioni polinomiale di secondo ordine nessuna torte polenta funzione non può eseguire questo tipo di regressione che usiamo la preelaborazione del bibliotecario imparare a creare un oggetto polinomiale il costruttore prende il grado di polinomiale come parametro poi trasformiamo le funzioni in un polinomio funzione con il metodo di trasformazione fit underscore facciamo un esempio più intuitivo. Considerate la caratteristica mostrata qui applicando il metodo che trasformiamo i dati che ora abbiamo una nuova serie di funzioni che vengono trasformate in versione trasformata delle nostre caratteristiche originali in quanto io cito i dati diventa più grande potremmo voler normalizzare più funzioni come scikit impariamo invece possiamo utilizzare il modulo di preelaborazione per semplificare molte attività ad esempio possiamo standardizzare ogni feature contemporaneamente importiamo scaler standard ci alleniamo l'oggetto in scala l'oggetto scala poi trasformano i dati in un nuovo frame di dati su una tasso x. scala di sottolineatura ci sono più metodi di normalizzazione disponibili nella libreria di pre - elaborazione così come altre trasformazioni possiamo semplificare il nostro codice utilizzando una libreria di pipeline ci sono molti passi per ottenere una previsione ad esempio la trasformazione polinomiale e la regressione lineare semplifichiamo il processo utilizzando una pipeline. Pipeline sequenzialmente effettua una serie di trasformazioni l'ultimo step effettua una previsione prima di importare tutti i moduli di cui abbiamo bisogno poi importiamo la pipeline della libreria che creiamo un elenco di toppi il primo elemento in toppia contiene il nome del modello di stimatore il secondo elemento contiene il costruttore modello che inseriamo l'elenco nel costruttore di pipeline abbiamo ora un oggetto pipeline che possiamo addestrare la pipeline applicando il metodo del treno all'oggetto pipeline possiamo anche produrre una previsione come beh. Il metodo normalizza i dati esegue una trasformazione polinomiale poi outmette una previsione.\"}],\n",
       " 'word_count': 691,\n",
       " 'character_count': 3970}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated = lt.translate(text = text, model_id = 'en-it')\n",
    "translated.get_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert json object into a paragraph of translated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In questo video copriremo la regressione polinomiale e i gasdotti. Cosa facciamo quando un modello lineare non è il migliore adatto per i nostri dati, analizziamo un altro tipo di regressione modello la regressione polinomiale che trasformiamo i nostri dati in un polinomio poi usa la regressione lineare per adattarsi ai parametri che discuteremo di pipeline pipeline sono in grado di semplificare il tuo codice. La regressione polinomiale è un caso particolare della regressione lineare generale questo metodo è benefico per descrivere le relazioni curvilinee ciò che è un rapporto curvilineo è ciò che si ottiene per quadratura o impostazione di termini di ordine superiore delle variabili predittiva nel modello che trasforma il dato il modello può essere quadratico che significa la variabile predittiva nel modello è quadrante usiamo una staffa per indicare come esponente questa è la regressione polinomiale di secondo ordine con una figura che rappresenta la funzione. Il modello può essere cubico che significa che la variabile predittiva è carina questa è la regressione polinomiale di terzo ordine che vediamo esaminando la figura che la funzione ha più variazione. Esiste anche regressioni polinomiali di ordine superiore quando un buon adattamento non è stato ottenuto secondo un secondo o terzo ordine possiamo vedere in cifre quanto i grafici cambiano quando modifichiamo l'ordine della regressione polinomiale il grado di regressione fa una grande differenza e può risultare in un adattamento migliore se scegli il giusto valore in tutti i casi il rapporto tra la variabile nel parametro è sempre lineare. Analizziamo un esempio dai nostri dati generiamo un modello di regressione polinomiale. In python lo facciamo utilizzando la funzione poli fit in questo esempio sviluppiamo una base modello di regressione polinomiale di terzo ordine possiamo stampare il modulo simbolico modello per il modello è dato dalla seguente espressione. Negativo un punto cinque cinque x. uno carino più duecento quattro punti x. uno squartato più otto diecimila sessanta sessanta x. uno più un punto tre volte sette volte dieci alla potenza di cinque possiamo anche avere una regressione lineare polinomiale multi - dimensionale l'espressione può diventare complicata qui sono solo alcuni dei termini per due dimensioni polinomiale di secondo ordine nessuna torte polenta funzione non può eseguire questo tipo di regressione che usiamo la preelaborazione del bibliotecario imparare a creare un oggetto polinomiale il costruttore prende il grado di polinomiale come parametro poi trasformiamo le funzioni in un polinomio funzione con il metodo di trasformazione fit underscore facciamo un esempio più intuitivo. Considerate la caratteristica mostrata qui applicando il metodo che trasformiamo i dati che ora abbiamo una nuova serie di funzioni che vengono trasformate in versione trasformata delle nostre caratteristiche originali in quanto io cito i dati diventa più grande potremmo voler normalizzare più funzioni come scikit impariamo invece possiamo utilizzare il modulo di preelaborazione per semplificare molte attività ad esempio possiamo standardizzare ogni feature contemporaneamente importiamo scaler standard ci alleniamo l'oggetto in scala l'oggetto scala poi trasformano i dati in un nuovo frame di dati su una tasso x. scala di sottolineatura ci sono più metodi di normalizzazione disponibili nella libreria di pre - elaborazione così come altre trasformazioni possiamo semplificare il nostro codice utilizzando una libreria di pipeline ci sono molti passi per ottenere una previsione ad esempio la trasformazione polinomiale e la regressione lineare semplifichiamo il processo utilizzando una pipeline. Pipeline sequenzialmente effettua una serie di trasformazioni l'ultimo step effettua una previsione prima di importare tutti i moduli di cui abbiamo bisogno poi importiamo la pipeline della libreria che creiamo un elenco di toppi il primo elemento in toppia contiene il nome del modello di stimatore il secondo elemento contiene il costruttore modello che inseriamo l'elenco nel costruttore di pipeline abbiamo ora un oggetto pipeline che possiamo addestrare la pipeline applicando il metodo del treno all'oggetto pipeline possiamo anche produrre una previsione come beh. Il metodo normalizza i dati esegue una trasformazione polinomiale poi outmette una previsione.\""
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = ''.join(list(json_normalize(translated.get_result()['translations'])['translation']))\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
